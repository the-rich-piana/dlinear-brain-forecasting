Args in experiment:
Namespace(is_training=1, model_id='Activity_32_8', model='DummyLinear', data='ActivityOrdered', root_path='./dataset/', data_path='session_0.h5', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=32, label_len=32, pred_len=8, individual=False, embed_type=0, enc_in=5000, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=128, patience=3, learning_rate=0.01, des='Exp', loss='mae', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Activity_32_8_DummyLinear_ActivityOrdered_ftM_sl32_ll32_pl8_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Brain data loaded: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Temporal split - Total time: 19081
Train: 0 to 16218 (85.0%)
Val: 16218 to 18126 (10.0%)
Test: 18126 to 19081 (5.0%)
Current split (train): 0 to 16218
Selected top 5000 neurons out of 6903 total
Selected neuron std range: 0.105 to 0.267
Final dataset shape: (16218, 5000)
Final data stats - Mean: 0.350, Std: 0.150
Sequences available: 16179
train 16179
Brain data loaded: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Temporal split - Total time: 19081
Train: 0 to 16218 (85.0%)
Val: 16218 to 18126 (10.0%)
Test: 18126 to 19081 (5.0%)
Current split (val): 16186 to 18126
Selected top 5000 neurons out of 6903 total
Selected neuron std range: 0.105 to 0.267
Final dataset shape: (1940, 5000)
Final data stats - Mean: 0.323, Std: 0.141
Sequences available: 1901
val 1901
Brain data loaded: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Temporal split - Total time: 19081
Train: 0 to 16218 (85.0%)
Val: 16218 to 18126 (10.0%)
Test: 18126 to 19081 (5.0%)
Current split (test): 18094 to 19081
Selected top 5000 neurons out of 6903 total
Selected neuron std range: 0.105 to 0.267
Final dataset shape: (987, 5000)
Final data stats - Mean: 0.356, Std: 0.150
Sequences available: 948
test 948
	iters: 100, epoch: 1 | loss: 1.5512531
	speed: 0.1029s/iter; left time: 119.5238s
Epoch: 1 cost time: 8.933571577072144
Epoch: 1, Steps: 126 | Train Loss: 2.1790084 Vali Loss: 1.5807010 Test Loss: 1.7565700
Validation loss decreased (inf --> 1.580701).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 1.4977833
	speed: 0.1290s/iter; left time: 133.5037s
Epoch: 2 cost time: 9.16393518447876
Epoch: 2, Steps: 126 | Train Loss: 1.5641353 Vali Loss: 1.5053056 Test Loss: 1.6659925
Validation loss decreased (1.580701 --> 1.505306).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.7581561
	speed: 0.1334s/iter; left time: 121.2626s
Epoch: 3 cost time: 9.317930221557617
Epoch: 3, Steps: 126 | Train Loss: 0.8178318 Vali Loss: 0.6712888 Test Loss: 0.7411305
Validation loss decreased (1.505306 --> 0.671289).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2374341
	speed: 0.1329s/iter; left time: 104.0713s
Epoch: 4 cost time: 9.336323976516724
Epoch: 4, Steps: 126 | Train Loss: 0.2721490 Vali Loss: 0.2169786 Test Loss: 0.2371495
Validation loss decreased (0.671289 --> 0.216979).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.0953082
	speed: 0.1352s/iter; left time: 88.8144s
Epoch: 5 cost time: 9.30041766166687
Epoch: 5, Steps: 126 | Train Loss: 0.1066156 Vali Loss: 0.0953995 Test Loss: 0.1026443
Validation loss decreased (0.216979 --> 0.095399).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.0871357
	speed: 0.1338s/iter; left time: 71.0224s
Epoch: 6 cost time: 9.309053421020508
Epoch: 6, Steps: 126 | Train Loss: 0.0870028 Vali Loss: 0.0899431 Test Loss: 0.0965119
Validation loss decreased (0.095399 --> 0.089943).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.0830128
	speed: 0.1319s/iter; left time: 53.4131s
Epoch: 7 cost time: 9.338793516159058
Epoch: 7, Steps: 126 | Train Loss: 0.0831242 Vali Loss: 0.0883608 Test Loss: 0.0947315
Validation loss decreased (0.089943 --> 0.088361).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.0815577
	speed: 0.1335s/iter; left time: 37.2517s
Epoch: 8 cost time: 9.266303539276123
Epoch: 8, Steps: 126 | Train Loss: 0.0813590 Vali Loss: 0.0877342 Test Loss: 0.0939056
Validation loss decreased (0.088361 --> 0.087734).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.0807354
	speed: 0.1330s/iter; left time: 20.3528s
Epoch: 9 cost time: 9.363422632217407
Epoch: 9, Steps: 126 | Train Loss: 0.0804554 Vali Loss: 0.0873441 Test Loss: 0.0935133
Validation loss decreased (0.087734 --> 0.087344).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.0794552
	speed: 0.1336s/iter; left time: 3.6063s
Epoch: 10 cost time: 9.239139080047607
Epoch: 10, Steps: 126 | Train Loss: 0.0799784 Vali Loss: 0.0872632 Test Loss: 0.0934205
Validation loss decreased (0.087344 --> 0.087263).  Saving model ...
Updating learning rate to 1.953125e-05
>>>>>>>testing : Activity_32_8_DummyLinear_ActivityOrdered_ftM_sl32_ll32_pl8_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Brain data loaded: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Temporal split - Total time: 19081
Train: 0 to 16218 (85.0%)
Val: 16218 to 18126 (10.0%)
Test: 18126 to 19081 (5.0%)
Current split (test): 18094 to 19081
Selected top 5000 neurons out of 6903 total
Selected neuron std range: 0.105 to 0.267
Final dataset shape: (987, 5000)
Final data stats - Mean: 0.356, Std: 0.150
Sequences available: 948
test 948
mse:0.015507406555116177, mae:0.09342054277658463, rse:0.8301377892494202, corr:[0.03588036 0.03115006 0.02695155 0.02413336 0.02209994 0.02038059
 0.01880859 0.01730889]
