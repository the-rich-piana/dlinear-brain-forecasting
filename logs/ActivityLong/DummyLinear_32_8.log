Args in experiment:
Namespace(is_training=1, train_only=False, model_id='Activity_32_8', model='DummyLinear', data='Activity', root_path='./dataset/', data_path='session_0.h5', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=32, label_len=32, pred_len=8, individual=False, embed_type=0, enc_in=5000, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=128, patience=3, learning_rate=0.01, des='Exp', loss='mae', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Activity_32_8_DummyLinear_Activity_ftM_sl32_ll32_pl8_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (13356, 5000)
Final data statistics - Mean: 0.347, Std: 0.149
train 13317
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (1908, 5000)
Final data statistics - Mean: 0.378, Std: 0.158
val 1869
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (3849, 5000)
Final data statistics - Mean: 0.325, Std: 0.143
test 3810
	iters: 100, epoch: 1 | loss: 1.6006521
	speed: 0.1296s/iter; left time: 121.9356s
Epoch: 1 cost time: 8.645241022109985
Epoch: 1, Steps: 104 | Train Loss: 2.1848796 Vali Loss: 1.7012947 Test Loss: 1.4549791
Validation loss decreased (inf --> 1.701295).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 1.5134742
	speed: 0.1393s/iter; left time: 116.6172s
Epoch: 2 cost time: 7.859563827514648
Epoch: 2, Steps: 104 | Train Loss: 1.5741344 Vali Loss: 1.5098860 Test Loss: 1.2777303
Validation loss decreased (1.701295 --> 1.509886).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.7179810
	speed: 0.1414s/iter; left time: 103.6720s
Epoch: 3 cost time: 7.917750597000122
Epoch: 3, Steps: 104 | Train Loss: 0.7160570 Vali Loss: 0.6972668 Test Loss: 0.5979860
Validation loss decreased (1.509886 --> 0.697267).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2212264
	speed: 0.1428s/iter; left time: 89.7907s
Epoch: 4 cost time: 8.00043272972107
Epoch: 4, Steps: 104 | Train Loss: 0.2692023 Vali Loss: 0.2552918 Test Loss: 0.2238583
Validation loss decreased (0.697267 --> 0.255292).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.0933747
	speed: 0.1416s/iter; left time: 74.3501s
Epoch: 5 cost time: 8.016875505447388
Epoch: 5, Steps: 104 | Train Loss: 0.1080131 Vali Loss: 0.1067922 Test Loss: 0.0969486
Validation loss decreased (0.255292 --> 0.106792).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.0849293
	speed: 0.1463s/iter; left time: 61.5772s
Epoch: 6 cost time: 8.345314264297485
Epoch: 6, Steps: 104 | Train Loss: 0.0870254 Vali Loss: 0.1001601 Test Loss: 0.0919204
Validation loss decreased (0.106792 --> 0.100160).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.0823175
	speed: 0.1438s/iter; left time: 45.5988s
Epoch: 7 cost time: 8.083023071289062
Epoch: 7, Steps: 104 | Train Loss: 0.0830924 Vali Loss: 0.0985823 Test Loss: 0.0906560
Validation loss decreased (0.100160 --> 0.098582).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.0807733
	speed: 0.1441s/iter; left time: 30.6889s
Epoch: 8 cost time: 8.028055429458618
Epoch: 8, Steps: 104 | Train Loss: 0.0813463 Vali Loss: 0.0979457 Test Loss: 0.0900163
Validation loss decreased (0.098582 --> 0.097946).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.0802990
	speed: 0.1432s/iter; left time: 15.6062s
Epoch: 9 cost time: 7.98654580116272
Epoch: 9, Steps: 104 | Train Loss: 0.0804568 Vali Loss: 0.0974580 Test Loss: 0.0898055
Validation loss decreased (0.097946 --> 0.097458).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.0811312
	speed: 0.1447s/iter; left time: 0.7236s
Epoch: 10 cost time: 8.177061796188354
Epoch: 10, Steps: 104 | Train Loss: 0.0799899 Vali Loss: 0.0973240 Test Loss: 0.0895748
Validation loss decreased (0.097458 --> 0.097324).  Saving model ...
Updating learning rate to 1.953125e-05
>>>>>>>testing : Activity_32_8_DummyLinear_Activity_ftM_sl32_ll32_pl8_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (3849, 5000)
Final data statistics - Mean: 0.325, Std: 0.143
test 3810
mse:0.014331348240375519, mae:0.08952903002500534
