Args in experiment:
Namespace(is_training=1, model_id='Informer_336_5', model='Informer', data='Activity', root_path='./dataset/', data_path='session_0.h5', features='M', target='OT', freq='m', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=5, individual=False, embed_type=0, enc_in=5000, dec_in=5000, c_out=5000, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=64, patience=3, learning_rate=0.01, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : Informer_336_5_Informer_Activity_ftM_sl336_ll48_pl5_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (13356, 5000)
Final data statistics - Mean: 0.347, Std: 0.149
train 13016
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (2244, 5000)
Final data statistics - Mean: 0.380, Std: 0.158
val 1904
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (4153, 5000)
Final data statistics - Mean: 0.326, Std: 0.144
test 3813
	iters: 100, epoch: 1 | loss: 30.1173534
	speed: 0.1829s/iter; left time: 353.2459s
	iters: 200, epoch: 1 | loss: 28.0604897
	speed: 0.1598s/iter; left time: 292.5987s
Epoch: 1 cost time: 33.68736004829407
Epoch: 1, Steps: 203 | Train Loss: 563.6604559 Vali Loss: 0.0168317 Test Loss: 0.0142394
Validation loss decreased (inf --> 0.016832).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 24.9998474
	speed: 0.3106s/iter; left time: 536.7844s
	iters: 200, epoch: 2 | loss: 23.1764393
	speed: 0.1591s/iter; left time: 259.0199s
Epoch: 2 cost time: 33.405463218688965
Epoch: 2, Steps: 203 | Train Loss: 25.0477162 Vali Loss: 0.0168093 Test Loss: 0.0141837
Validation loss decreased (0.016832 --> 0.016809).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 21.8641911
	speed: 0.3103s/iter; left time: 473.2454s
	iters: 200, epoch: 3 | loss: 20.0737610
	speed: 0.1594s/iter; left time: 227.1141s
Epoch: 3 cost time: 33.38798975944519
Epoch: 3, Steps: 203 | Train Loss: 21.5408473 Vali Loss: 0.0169149 Test Loss: 0.0137044
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 20.3443108
	speed: 0.2995s/iter; left time: 395.9652s
	iters: 200, epoch: 4 | loss: 20.1035137
	speed: 0.1596s/iter; left time: 195.0445s
Epoch: 4 cost time: 33.48571801185608
Epoch: 4, Steps: 203 | Train Loss: 19.8802588 Vali Loss: 0.0166659 Test Loss: 0.0133114
Validation loss decreased (0.016809 --> 0.016666).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 19.0464497
	speed: 0.3139s/iter; left time: 351.2372s
	iters: 200, epoch: 5 | loss: 19.1363106
	speed: 0.1604s/iter; left time: 163.4253s
Epoch: 5 cost time: 33.64964842796326
Epoch: 5, Steps: 203 | Train Loss: 19.1249961 Vali Loss: 0.0163272 Test Loss: 0.0136870
Validation loss decreased (0.016666 --> 0.016327).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 19.0657330
	speed: 0.3116s/iter; left time: 285.3817s
	iters: 200, epoch: 6 | loss: 18.0753441
	speed: 0.1601s/iter; left time: 130.6562s
Epoch: 6 cost time: 33.475820779800415
Epoch: 6, Steps: 203 | Train Loss: 18.6966399 Vali Loss: 0.0160396 Test Loss: 0.0138804
Validation loss decreased (0.016327 --> 0.016040).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 18.6999779
	speed: 0.3126s/iter; left time: 222.8841s
	iters: 200, epoch: 7 | loss: 18.2437172
	speed: 0.1598s/iter; left time: 97.9524s
Epoch: 7 cost time: 33.5023193359375
Epoch: 7, Steps: 203 | Train Loss: 18.4860684 Vali Loss: 0.0160826 Test Loss: 0.0139252
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 18.0489788
	speed: 0.2988s/iter; left time: 152.4108s
	iters: 200, epoch: 8 | loss: 18.5207195
	speed: 0.1612s/iter; left time: 66.0820s
Epoch: 8 cost time: 33.716975688934326
Epoch: 8, Steps: 203 | Train Loss: 18.3738607 Vali Loss: 0.0160970 Test Loss: 0.0138571
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 17.8965740
	speed: 0.3005s/iter; left time: 92.2633s
	iters: 200, epoch: 9 | loss: 18.2259045
	speed: 0.1597s/iter; left time: 33.0580s
Epoch: 9 cost time: 33.50009274482727
Epoch: 9, Steps: 203 | Train Loss: 18.3004997 Vali Loss: 0.0161837 Test Loss: 0.0136353
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : Informer_336_5_Informer_Activity_ftM_sl336_ll48_pl5_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Loaded preprocessed data: (19081, 6903)
Original neurons: 7673, Processed neurons: 6903
Data range: 0.000 to 1.000
Selected top 5000 neurons out of 6903 preprocessed neurons
Final dataset shape: (4153, 5000)
Final data statistics - Mean: 0.326, Std: 0.144
test 3813
mse:0.013880381360650063, mae:0.09004493802785873, rse:0.8232881426811218, corr:[ 1.6225205e-03 -7.3345960e-05  1.2722597e-03 -1.7506316e-03
 -9.7411510e-04]
